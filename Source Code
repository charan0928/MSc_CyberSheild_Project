SNORT INSTALLATION
 apt-get update //To update
 apt install snort // installation
 snort -V // to check version
 
SNORT CONFIGURATION
 /etc/snort/snort.conf // Configuration file location
 /etc/snort/rules //Rules folders
 
 //Rules added in local.rules
 alert tcp any any -> any 80 (msg:"Possible Credential Stuffing Attack - Multiple Failed Login Attempts"; flow:to_server,established; content:"POST"; http_method; content:"/login"; http_uri; content:"username="; http_client_body; threshold:type limit, track by_src, count 5, seconds 60; priority:1; sid:1000001; rev:1;)
 alert tcp $EXTERNAL_NET any -> $HOME_NET 80 (msg:"SQL Injection Attempt"; flow:to_server,established; content:"' OR '1'='1"; nocase; classtype:web-application-attack; priority:1; sid:1000002; rev:1;)

 /var/log/snort/ // where the snort.log file stores the logs
 snort -A console -q -u snort -g snort -c /etc/snort/snort.conf -i ens37 //

INSTALLATION OF ELASTICSEARCH.
curl -fsSL https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - //To import the Elasticsearch public GPG key into APT
echo "deb https://artifacts.elastic.co/packages/7.x/apt stable main" | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.list //for new sources
sudo apt update
sudo apt install elasticsearch
/etc/elasticsearch //Directory yml files
// Configuration file of Elasticsearch
sudo nano /etc/elasticsearch/elasticsearch.yml
# ---------------------------------- Network -----------------------------------
#
# Set the bind address to a specific IP (IPv4 or IPv6):
#
network.host: localhost

sudo systemctl start elasticsearch
sudo systemctl enable elasticsearch
curl -X GET 'http://localhost:9200' // to verify Elasticsearch

INSTALLATION OF KIBANA
 sudo apt install kibana
 sudo systemctl start kibana
 sudo systemctl enable kibana
 sudo systemctl status kibana
 
LOGSTASH INSTALLATION 
 sudo apt install logstash
 /etc/logstash/conf.d // configuration files are located in this path
 
 //Input file 
 input {
   beats {
	port => 5044
   }
 }
 
 //Below mentioned code is for filter the logs//
 filter {
  if [app] == "snort" {
    dissect {
      mapping => {
        "message" => "%{ts} [%{field1}] [%{Generator_ID}:%{Signature_ID}:%{Revision}] %{Signature} [%{field3}] [Classification: %{Classification}] [Priority: %{Priority}] %{restOfLine}"
      }
    }

    grok {
      match => {
        "restOfLine" => "^{(?<Protocol>.*?)\}\s(?<Source_IP>.*?)\s->\s(?<Destination_IP>.*)"
      }
    }
    grok {
      match => {
        "Source_IP" => "%{IP:src_ip}(:%{INT:src_port})?"
      }
    }

    date {
      match => [ "ts", "MM/dd-HH:mm:ss.SSSSSS" ]
      target => "@timestamp"
    }

    geoip {
      source => "src_ip"
      target => "geo"
      database => "/usr/share/logstash/data/plugins/filters/geoip/1722340042/GeoLite2-ASN.mmdb"
    }

    mutate {
      add_field => {
        "[Location]" => "%{[geo][latitude]},%{[geo][longitude]}"
      }
    }
  }
}

//Output file for logstash
output {
   elasticsearch {
     hosts => ["http://localhost:9200"]
	 index => "snort-logs-%[+YYYY.MM.dd]"
	}
	stdout { codec => rubydebug }
}

sudo /usr/share/logstash/bin/logstash --path.settings /etc/logstash --config.test_and_exit -f /etc/logstash/conf.d/   //configuration test
  sudo systemctl start logstash
  sudo systemctl enable logstash

FILEBEAT SERVICE
 sudo apt install filebeat
 //Filebeat Configuration file
 # ============================== Filebeat inputs ===============================

filebeat.inputs:

# Each - is an input. Most options can be set at the input level, so
# you can use different inputs for various configurations.
# Below are the input specific configurations.

# filestream is an input for collecting log messages from files.
#- type: filestream
- type: filestream
  # Unique ID among all inputs, an ID is required.
  id: my-filestream-id

  # Change to true to enable this input configuration.
  enabled: true

  # Paths that should be crawled and fetched. Glob based paths.
  paths:
    #- /var/log/*.log
    - /root/snort_log.log
    #- c:\programdata\elasticsearch\logs\*
  fields_under_root: true
  fields:
    app: snort
# ------------------------------ Logstash Output -------------------------------
output.logstash:
  # The Logstash hosts
  hosts: ["localhost:5044"]

 sudo filebeat setup --index-management -E output.logstash.enabled=false -E 'output.elasticsearch.hosts=["localhost:9200"]' // Loading the index template
 sudo systemctl start filebeat
 sudo systemctl enable filebeat
 curl -XGET 'http://localhost:9200/snort-logs-*/_search?pretty' //validation
 
ELASTALERT
 sudo apt-get install python3-pip python3-venv libffi-dev libssl-dev //libraray files
 pip install elastalert
 apt-cache policy git // find and handle packages associated with git
 â€œgit clone http://github.com/Yelp/elastalert.git // to clone repo
 pip install "setuptools>=11.3"
 python setup.py install
 pip install "elasticsearch>=5.0.0"
 elastalert-create-index // Index creation for elastalert
 // Configuration file for Rules
 rules_folder: example_rules

# How often ElastAlert will query Elasticsearch
# The unit can be anything from weeks to seconds
run_every:
  minutes: 1
# ElastAlert will buffer results from the most recent
# period of time, in case some log sources are not in real time
buffer_time:
  minutes: 15

# The Elasticsearch hostname for metadata writeback
# Note that every rule can have its own Elasticsearch host
es_host: localhost

# The Elasticsearch port
es_port: 9200

writeback_index: elastalert_status
writeback_alias: elastalert_alerts

alert_time_limit:
  days: 2

// Rules based on Frequency

# (Required)
# Rule name, must be unique
name: Frequency

# (Required)
# Type of alert.
# the frequency rule type alerts when num_events events occur with timeframe time
type: frequency

# (Required)
# Index to search, wildcard supported

#index: logstash-*
index: snort-logs-*

# (Required, frequency specific)
# Alert when this many documents matching the query occur within a timeframe
num_events: 50

# (Required, frequency specific)
# num_events must occur within this amount of time to trigger an alert
timeframe:
  hours: 5

# (Required)
# A list of Elasticsearch filters used for find events
# These filters are joined with AND and nested in a filtered query
# For more info: http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/query-dsl.html
#filter:
#- term:
#    some_field: "some_value"
filter:
- query:
    query_string:
      query: "Priority: 3"

# (Required)
# The alert is use when a match is found
alert:
- "email"

# (required, email specific)
# a list of email addresses to send alerts to
email:
- "sandy12345sandeep12345@gmail.com"

smtp_host: "smtp.gmail.com"
smtp_port: 587
smtp_ssl: false
from_addr: "sandy12345sandeep12345@gmail.com"
smtp_auth_file: "/etc/elastalert/smtp_auth_file.yaml"


//SMTP authorization file SMTP_AUTH_FILE.YAML
user: "sandy12345sandeep12345@gmail.com"
password: "dxfw isar jvdn dxdn"


 elastalert-test-rule example_rules/example_frequency.yaml // Testing rules created in ELASTALERT
 python3 -m elastalert.elastalert --verbose --rule example_frequency.yaml // To start and test ELASTALERT
